diff --git a/src/main/java/org/apache/commons/math3/random/BitsStreamGenerator.java b/src/main/java/org/apache/commons/math3/random/BitsStreamGenerator.java
index 33d350cb1..5d4a01c10 100644
--- a/src/main/java/org/apache/commons/math3/random/BitsStreamGenerator.java
+++ b/src/main/java/org/apache/commons/math3/random/BitsStreamGenerator.java
@@ -166,5 +149,7 @@ public abstract class BitsStreamGenerator
     public void clear() {
         nextGaussian = Double.NaN;
     }
-
 }
+As classifiers, decision trees perform very well when there are relatively few features in the dataset. The model also does well when you can approximate a dataset with a tree structure.
+Decision trees are prone to overfitting and can also be biased towards the classes that have greater representation in the dataset.
+Our dataset contains a large number of features (103), which is within the range of what the decision tree classifier can handle. Decision trees are also able to naturally model our problem (students passing and failing an exam), which makes it a good candidate to begin with. 
\ No newline at end of file
